{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "![LSTM](imgs/LSTM3-chain.png)\n",
    "\n",
    "![LSTM](imgs/LSTM2-notation.png)\n",
    "\n",
    "\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-f.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-i.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-C.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pytorch documentation\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "    c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\    \n",
    "    h_t = o_t * \\tanh(c_t) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5005,  1.3481,  0.6288],\n",
       "         [-1.8252,  1.7253,  1.2257]],\n",
       "\n",
       "        [[-0.5552,  0.4597, -1.0065],\n",
       "         [-0.5016,  1.9903,  0.2234]],\n",
       "\n",
       "        [[ 0.3214, -0.5680, -0.5147],\n",
       "         [-1.3167,  0.6508, -0.8881]],\n",
       "\n",
       "        [[-1.1084,  0.0401,  0.8550],\n",
       "         [ 1.5682,  0.2143, -1.2317]],\n",
       "\n",
       "        [[-0.3560,  0.5371, -0.0902],\n",
       "         [-0.2286, -3.4979, -0.1931]],\n",
       "\n",
       "        [[ 1.1518,  0.6028, -0.2782],\n",
       "         [-1.8239, -0.6287,  0.7224]],\n",
       "\n",
       "        [[-2.1469,  0.2663,  2.7176],\n",
       "         [ 0.7877, -0.3495, -0.0896]],\n",
       "\n",
       "        [[ 0.5612, -1.3012, -0.5063],\n",
       "         [ 0.0898,  0.4572, -2.1849]],\n",
       "\n",
       "        [[ 1.6293,  0.5466, -1.5969],\n",
       "         [ 1.6866, -0.0928,  0.5817]],\n",
       "\n",
       "        [[-0.5879, -1.0575,  0.0957],\n",
       "         [-1.7408,  0.5495,  0.2363]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "input_size = 3\n",
    "hidden_size = 4 \n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hidden_0 = (h_0, c_0)\n",
    "hidden_0 = (torch.zeros(1, batch_size, hidden_size), torch.zeros(1, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3737e-01,  5.6302e-03, -4.9816e-02, -2.0004e-01],\n",
       "         [-2.3011e-02, -3.5329e-02, -7.8206e-02, -3.6055e-01]],\n",
       "\n",
       "        [[ 3.2316e-01, -2.3466e-02, -2.0158e-01, -7.5211e-02],\n",
       "         [ 2.1199e-01, -7.7585e-02, -1.8131e-01, -2.9865e-01]],\n",
       "\n",
       "        [[ 3.0042e-01, -3.4779e-03, -1.4621e-01,  3.2667e-02],\n",
       "         [ 2.3426e-01, -8.7992e-02, -2.6517e-01, -1.7886e-01]],\n",
       "\n",
       "        [[ 9.8791e-02, -1.0915e-02, -1.1357e-01, -2.4487e-01],\n",
       "         [ 3.9601e-01, -1.5478e-02, -1.7707e-01,  9.7502e-02]],\n",
       "\n",
       "        [[ 1.8468e-01, -4.0864e-02, -1.6821e-01, -1.8100e-01],\n",
       "         [ 1.4669e-01,  7.8331e-03, -1.0240e-01,  2.5374e-01]],\n",
       "\n",
       "        [[ 3.3929e-01, -9.0723e-03, -1.2828e-01,  5.8955e-03],\n",
       "         [-5.6789e-02,  1.4347e-03, -1.2996e-01, -6.6268e-03]],\n",
       "\n",
       "        [[-5.3453e-02, -2.2917e-02, -3.3337e-02, -4.1277e-01],\n",
       "         [ 9.6413e-02, -1.0945e-03, -8.3383e-02,  9.3607e-02]],\n",
       "\n",
       "        [[-5.8260e-02, -3.1421e-02, -4.9739e-02, -2.7877e-04],\n",
       "         [ 3.2461e-01, -9.5226e-03, -3.2062e-01,  1.1195e-01]],\n",
       "\n",
       "        [[ 2.7262e-01, -1.0463e-02, -1.6529e-01,  1.2880e-01],\n",
       "         [ 2.9688e-01,  5.5230e-02, -6.3845e-02,  1.5390e-01]],\n",
       "\n",
       "        [[ 6.4429e-02, -3.7959e-03, -1.2873e-01,  1.2845e-01],\n",
       "         [ 1.7857e-01,  6.0781e-02, -1.3523e-01, -1.3868e-01]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to put hidden inputs to zeros, there is no need to provide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3737e-01,  5.6302e-03, -4.9816e-02, -2.0004e-01],\n",
       "         [-2.3011e-02, -3.5329e-02, -7.8206e-02, -3.6055e-01]],\n",
       "\n",
       "        [[ 3.2316e-01, -2.3466e-02, -2.0158e-01, -7.5211e-02],\n",
       "         [ 2.1199e-01, -7.7585e-02, -1.8131e-01, -2.9865e-01]],\n",
       "\n",
       "        [[ 3.0042e-01, -3.4779e-03, -1.4621e-01,  3.2667e-02],\n",
       "         [ 2.3426e-01, -8.7992e-02, -2.6517e-01, -1.7886e-01]],\n",
       "\n",
       "        [[ 9.8791e-02, -1.0915e-02, -1.1357e-01, -2.4487e-01],\n",
       "         [ 3.9601e-01, -1.5478e-02, -1.7707e-01,  9.7502e-02]],\n",
       "\n",
       "        [[ 1.8468e-01, -4.0864e-02, -1.6821e-01, -1.8100e-01],\n",
       "         [ 1.4669e-01,  7.8331e-03, -1.0240e-01,  2.5374e-01]],\n",
       "\n",
       "        [[ 3.3929e-01, -9.0723e-03, -1.2828e-01,  5.8955e-03],\n",
       "         [-5.6789e-02,  1.4347e-03, -1.2996e-01, -6.6268e-03]],\n",
       "\n",
       "        [[-5.3453e-02, -2.2917e-02, -3.3337e-02, -4.1277e-01],\n",
       "         [ 9.6413e-02, -1.0945e-03, -8.3383e-02,  9.3607e-02]],\n",
       "\n",
       "        [[-5.8260e-02, -3.1421e-02, -4.9739e-02, -2.7877e-04],\n",
       "         [ 3.2461e-01, -9.5226e-03, -3.2062e-01,  1.1195e-01]],\n",
       "\n",
       "        [[ 2.7262e-01, -1.0463e-02, -1.6529e-01,  1.2880e-01],\n",
       "         [ 2.9688e-01,  5.5230e-02, -6.3845e-02,  1.5390e-01]],\n",
       "\n",
       "        [[ 6.4429e-02, -3.7959e-03, -1.2873e-01,  1.2845e-01],\n",
       "         [ 1.7857e-01,  6.0781e-02, -1.3523e-01, -1.3868e-01]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last output is the output of RRR. We can get it by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0644, -0.0038, -0.1287,  0.1285],\n",
       "        [ 0.1786,  0.0608, -0.1352, -0.1387]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convient to have batches as the first dimension of the input. One can do it by adding `batch_first=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7090,  0.6713, -0.2927],\n",
       "         [-0.0044,  1.1004,  0.0753],\n",
       "         [ 0.3129, -1.2979,  0.8589],\n",
       "         [ 0.1603, -2.1742, -0.6558],\n",
       "         [-0.1733, -0.2667,  1.2018],\n",
       "         [-0.0623, -0.3800, -0.8426],\n",
       "         [ 1.7070,  0.4900,  0.1576],\n",
       "         [-0.3988, -0.4197, -0.3228],\n",
       "         [-0.1885,  0.5896,  0.2061],\n",
       "         [-0.0698, -1.6279,  1.2114]],\n",
       "\n",
       "        [[ 0.7737, -0.4161,  1.3371],\n",
       "         [-0.9493, -1.3784,  0.1852],\n",
       "         [-0.3857, -0.8651, -0.7796],\n",
       "         [ 0.2108, -0.6816, -0.0608],\n",
       "         [-0.1896, -0.2920,  1.3720],\n",
       "         [ 0.8461,  0.7577, -0.8664],\n",
       "         [ 0.6864, -1.4687,  0.1705],\n",
       "         [-0.4180, -0.8376, -0.8481],\n",
       "         [ 0.1751, -0.4141,  0.8335],\n",
       "         [-0.3939,  0.0695, -0.4448]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_batch_first = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True) \n",
    "inputs_batch_first = torch.randn(batch_size, seq_len, input_size)\n",
    "inputs_batch_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5140e-01,  6.1555e-02, -1.1835e-01, -1.0888e-01],\n",
       "         [ 9.2535e-02,  9.7749e-02, -5.7696e-02, -1.1671e-01],\n",
       "         [ 4.1922e-01,  8.7856e-02, -1.6694e-01,  2.5797e-02],\n",
       "         [ 5.0504e-01,  5.1214e-04, -2.8201e-01,  1.3873e-01],\n",
       "         [ 5.1953e-01,  1.0621e-01, -7.2846e-02,  8.3523e-02],\n",
       "         [ 3.3213e-01,  6.2645e-02, -1.7759e-01,  1.8347e-02],\n",
       "         [ 2.8936e-02,  5.7122e-02, -8.4806e-02,  1.2232e-01],\n",
       "         [ 2.5301e-01,  7.4532e-02, -2.1351e-01,  5.7084e-03],\n",
       "         [ 2.2063e-01,  1.1057e-01, -1.1541e-01, -2.4869e-02],\n",
       "         [ 5.4895e-01,  7.3016e-02, -2.1767e-01,  7.1727e-02]],\n",
       "\n",
       "        [[ 2.5289e-01,  6.8711e-02,  4.2039e-02,  7.6471e-02],\n",
       "         [ 4.9469e-01, -2.5324e-02, -1.9043e-01,  4.7053e-02],\n",
       "         [ 4.1987e-01, -4.4419e-02, -2.5495e-01,  6.1344e-04],\n",
       "         [ 4.1429e-01, -1.6326e-02, -2.4534e-01,  7.3951e-02],\n",
       "         [ 4.9910e-01,  1.0680e-01, -7.8427e-02,  7.2204e-02],\n",
       "         [ 8.0416e-02,  5.8543e-02, -9.1700e-02,  1.7329e-02],\n",
       "         [ 3.6995e-01,  4.8609e-02, -2.1248e-01,  1.2763e-01],\n",
       "         [ 3.7527e-01,  6.3979e-03, -2.6279e-01,  3.4952e-03],\n",
       "         [ 4.3394e-01,  7.2709e-02, -1.5661e-01,  7.4723e-02],\n",
       "         [ 3.1237e-01,  7.4881e-02, -1.8817e-01, -2.3086e-02]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm_batch_first(inputs_batch_first)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the finial output by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5489,  0.0730, -0.2177,  0.0717],\n",
       "        [ 0.3124,  0.0749, -0.1882, -0.0231]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[54, 41, 40, 11, 97, 71, 54, 60, 62, 33],\n",
       "        [51, 81, 53, 99, 14, 62, 77, 36, 60, 87]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = 100\n",
    "sentences = torch.randint(dict_size, (batch_size, seq_len))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(dict_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1924,  0.4054, -0.4470],\n",
       "         [-0.1768, -0.9867, -1.7221],\n",
       "         [-2.0614,  0.8953,  0.7218],\n",
       "         [-0.8199,  0.3928, -1.0932],\n",
       "         [ 0.9946,  0.1844,  0.9679],\n",
       "         [-1.8959, -0.5845,  1.9252],\n",
       "         [-1.1924,  0.4054, -0.4470],\n",
       "         [ 1.0142, -0.8709,  0.5223],\n",
       "         [-0.5081, -0.1358,  0.5295],\n",
       "         [ 0.9045,  1.7195,  0.2877]],\n",
       "\n",
       "        [[ 0.5203,  0.2844, -0.0147],\n",
       "         [ 1.0125,  0.9800,  0.7400],\n",
       "         [-1.0629, -0.0370,  0.1805],\n",
       "         [ 0.1748,  0.3632, -0.1491],\n",
       "         [-1.4453, -0.1103,  0.7742],\n",
       "         [-0.5081, -0.1358,  0.5295],\n",
       "         [ 0.7598,  0.7898,  1.3319],\n",
       "         [-0.9852, -0.3627,  0.0721],\n",
       "         [ 1.0142, -0.8709,  0.5223],\n",
       "         [-0.1946,  1.6898, -0.6985]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_embedded = embedding(sentences)\n",
    "sentences_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0020,  0.0802,  0.0134,  0.0142],\n",
       "        [ 0.0772,  0.0908, -0.0691, -0.0944]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, _ = lstm_batch_first(sentences_embedded)\n",
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento del lenguaje natural\n",
    "\n",
    "Tenemos un dataset que tiene textos que queremos evaluar si son tóxicos o no tóxicos. Este dataset puedes bajarlo del siguiente enlace \n",
    "[aquí](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_df = pd.read_csv(\"data/jigsaw-toxic-comment-classification-challenge/train.csv\")[:1000]\n",
    "comments_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>\"\\n\\nNo not really. We may ask that the mentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>\"\\nHaha, you're fine. I mean, you're allowed t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text\n",
       "744  \"\\n\\nNo not really. We may ask that the mentio...\n",
       "981  \"\\nHaha, you're fine. I mean, you're allowed t..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label_colnames = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(comments_df[['comment_text']], comments_df[label_colnames], random_state=667)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "class TextPreprocessor:\n",
    "        \n",
    "    def transfrom_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(BAD_SYMBOLS_RE, \" \", text) # process bad symbols\n",
    "        # text = \" \".join([STEMMER.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda text: self.transfrom_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "X_train_preprocessed = preprocessor.transform(X_train['comment_text'])\n",
    "X_test_preprocessed = preprocessor.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "No not really. We may ask that the mention of fat being the fire source of the cremation of millions be reconsidered though - along with a few other items. The fat cremation \"\"wiki fact\"\" is citable ( www.hdot - Emory U no less, Lipstadt) but doubtful. If the same science was applied to the holocaust as say the tinfoilers or flat earthers the deniers would be overjoyed. Be careful as to who gets the nutty fringe tinfoil label in the end. You get the permits and we'll bring the shovels. 159.105.80.141  \"\n",
      "   no not really  we may ask that the mention of fat being the fire source of the cremation of millions be reconsidered though   along with a few other items  the fat cremation   wiki fact   is citable   www hdot   emory u no less  lipstadt  but doubtful  if the same science was applied to the holocaust as say the tinfoilers or flat earthers the deniers would be overjoyed  be careful as to who gets the nutty fringe tinfoil label in the end  you get the permits and we ll bring the shovels  159 105 80 141   \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[0])\n",
    "print(X_train_preprocessed.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Haha, you're fine. I mean, you're allowed to do it, but I'm just selfish, I guess. =) I really appreciate your kindness, though. And I really respect that you asked, because when other signatures that were borrowed, no one let me know or gave me any credit! So I feel badly that since you asked, you'd feel really badly about doing it now, haha. But I can help you figure out a nice one or pick out some fun colors. Have a great day, and happy Wikying! τ \"\n",
      "  haha  you re fine  i mean  you re allowed to do it  but i m just selfish  i guess     i really appreciate your kindness  though  and i really respect that you asked  because when other signatures that were borrowed  no one let me know or gave me any credit  so i feel badly that since you asked  you d feel really badly about doing it now  haha  but i can help you figure out a nice one or pick out some fun colors  have a great day  and happy wikying     \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[1])\n",
    "print(X_train_preprocessed.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(text):\n",
    "    word_set = set()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "    word_list = [\"<UNK>\", \"<PAD>\"] + sorted(list(word_set))\n",
    "    word2idx = {word_list[idx]: idx for idx in range(len(word_list))}\n",
    "    idx2word = {idx: word_list[idx] for idx in range(len(word_list))}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2idx = None\n",
    "        self.idx2word = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        text = \" \".join(X)\n",
    "        self.word2idx, self.idx2word = create_dicts(text)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.transform_line(line) for line in X]\n",
    "        \n",
    "    def transform_line(self, line):\n",
    "        return [self.word2idx.get(word, 0) for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.transform(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutter:\n",
    "\n",
    "    def __init__(self, size=150):\n",
    "        self.size = size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        new_X = []\n",
    "        for line in X:\n",
    "            new_line = line[:self.size]\n",
    "            new_line = new_line + [1] * (self.size - len(new_line))\n",
    "            new_X.append(new_line)\n",
    "        return new_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = Cutter()\n",
    "X_train_cutted = cutter.transform(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(y_train.values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.tensor(X_train_cutted), torch.from_numpy(y_train.values).float())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, dict_size, output_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(dict_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeded)\n",
    "        lstm_out = lstm_out[:, -1]        \n",
    "        logits = self.fc(lstm_out)\n",
    "        out = self.sigmoid(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(tokenizer.word2idx)\n",
    "output_size = len(label_colnames)\n",
    "embedding_dim = 3\n",
    "hidden_dim = 4\n",
    "\n",
    "lstm_model = LSTMModel(dict_size, output_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([750, 150])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch = torch.tensor(X_train_cutted)\n",
    "X_train_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3698, 0.4937, 0.4490, 0.4962, 0.5455, 0.5104],\n",
       "        ...,\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3487, 0.4972, 0.4374, 0.5157, 0.5510, 0.4891]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3244, 0.5134, 0.4215, 0.5172, 0.5321, 0.4569],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3403, 0.5075, 0.4291, 0.5101, 0.5384, 0.4730],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3462, 0.4995, 0.4397, 0.5063, 0.5461, 0.4869],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3608, 0.4913, 0.4453, 0.5036, 0.5682, 0.4979],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3407, 0.5039, 0.4348, 0.5071, 0.5418, 0.4783],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131],\n",
       "        [0.3748, 0.4946, 0.4506, 0.4891, 0.5426, 0.5131]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "input_data, labels = dataiter.next()\n",
    "lstm_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    for batch_i, (input_data, labels) in enumerate(train_loader):\n",
    "        # Zero gradients (just in case)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate predictions\n",
    "        output = lstm_model(input_data) \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        ## Backward propagation\n",
    "        loss.backward()\n",
    "        ## Upade weights\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "input_data, labels = dataiter.next()\n",
    "lstm_model(input_data) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
