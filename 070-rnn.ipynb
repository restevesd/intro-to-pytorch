{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "![LSTM](imgs/LSTM3-chain.png)\n",
    "\n",
    "![LSTM](imgs/LSTM2-notation.png)\n",
    "\n",
    "\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-f.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-i.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-C.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pytorch documentation\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "    c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\    \n",
    "    h_t = o_t * \\tanh(c_t) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to define LSTM layer in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4555,  0.7465, -0.9415],\n",
       "         [-1.1096, -0.6533,  0.7203]],\n",
       "\n",
       "        [[-0.3836, -0.3617,  0.8822],\n",
       "         [ 0.1445,  1.7087,  0.3034]],\n",
       "\n",
       "        [[ 1.8307, -0.7956, -0.9783],\n",
       "         [-0.9901,  0.6492, -0.4896]],\n",
       "\n",
       "        [[ 1.0044,  0.1137, -0.6549],\n",
       "         [ 0.4077,  0.1702,  1.5962]],\n",
       "\n",
       "        [[ 0.4822,  0.1461,  0.8689],\n",
       "         [ 1.3198, -0.6380, -0.6823]],\n",
       "\n",
       "        [[ 0.0273, -0.4202, -0.7030],\n",
       "         [ 0.7543,  0.8357, -1.2389]],\n",
       "\n",
       "        [[-0.1848, -0.9312, -0.7273],\n",
       "         [-0.6170, -1.4889, -1.0162]],\n",
       "\n",
       "        [[-0.0296,  1.4472, -0.3702],\n",
       "         [ 2.3862,  0.8240, -0.9050]],\n",
       "\n",
       "        [[-1.3517,  1.0657,  0.5884],\n",
       "         [ 0.4590, -0.5893, -0.8926]],\n",
       "\n",
       "        [[-0.4153, -1.4629,  0.3760],\n",
       "         [ 1.6195, -0.4756,  0.7551]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "input_size = 3\n",
    "hidden_size = 4 \n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hidden_0 = (h_0, c_0)\n",
    "hidden_0 = (torch.zeros(1, batch_size, hidden_size), torch.zeros(1, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0247,  0.1507, -0.0803,  0.0449],\n",
       "         [-0.1006, -0.0147,  0.2621,  0.0776]],\n",
       "\n",
       "        [[-0.0708,  0.0842,  0.2027,  0.0979],\n",
       "         [-0.1715,  0.0161,  0.2130,  0.0533]],\n",
       "\n",
       "        [[ 0.1210,  0.1712,  0.1224,  0.2107],\n",
       "         [-0.2133,  0.0502,  0.1296,  0.0397]],\n",
       "\n",
       "        [[ 0.0395,  0.2172,  0.1012,  0.1445],\n",
       "         [ 0.0055,  0.0087,  0.2190,  0.0872]],\n",
       "\n",
       "        [[ 0.0158,  0.1562,  0.2057,  0.1249],\n",
       "         [ 0.1115,  0.1357,  0.1783,  0.1808]],\n",
       "\n",
       "        [[-0.0521,  0.1595,  0.1960,  0.1263],\n",
       "         [-0.0299,  0.1944,  0.0040,  0.0803]],\n",
       "\n",
       "        [[-0.0573,  0.1361,  0.2098,  0.1501],\n",
       "         [-0.0741,  0.1172,  0.1170,  0.1334]],\n",
       "\n",
       "        [[-0.1661,  0.1290,  0.0922,  0.0616],\n",
       "         [ 0.0158,  0.2274, -0.0029,  0.1340]],\n",
       "\n",
       "        [[-0.2746, -0.0124,  0.2156,  0.0354],\n",
       "         [-0.0274,  0.2116,  0.0389,  0.1419]],\n",
       "\n",
       "        [[ 0.0211,  0.0557,  0.2625,  0.1923],\n",
       "         [ 0.1903,  0.2360,  0.1382,  0.1859]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to put hidden inputs to zeros, there is no need to provide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0247,  0.1507, -0.0803,  0.0449],\n",
       "         [-0.1006, -0.0147,  0.2621,  0.0776]],\n",
       "\n",
       "        [[-0.0708,  0.0842,  0.2027,  0.0979],\n",
       "         [-0.1715,  0.0161,  0.2130,  0.0533]],\n",
       "\n",
       "        [[ 0.1210,  0.1712,  0.1224,  0.2107],\n",
       "         [-0.2133,  0.0502,  0.1296,  0.0397]],\n",
       "\n",
       "        [[ 0.0395,  0.2172,  0.1012,  0.1445],\n",
       "         [ 0.0055,  0.0087,  0.2190,  0.0872]],\n",
       "\n",
       "        [[ 0.0158,  0.1562,  0.2057,  0.1249],\n",
       "         [ 0.1115,  0.1357,  0.1783,  0.1808]],\n",
       "\n",
       "        [[-0.0521,  0.1595,  0.1960,  0.1263],\n",
       "         [-0.0299,  0.1944,  0.0040,  0.0803]],\n",
       "\n",
       "        [[-0.0573,  0.1361,  0.2098,  0.1501],\n",
       "         [-0.0741,  0.1172,  0.1170,  0.1334]],\n",
       "\n",
       "        [[-0.1661,  0.1290,  0.0922,  0.0616],\n",
       "         [ 0.0158,  0.2274, -0.0029,  0.1340]],\n",
       "\n",
       "        [[-0.2746, -0.0124,  0.2156,  0.0354],\n",
       "         [-0.0274,  0.2116,  0.0389,  0.1419]],\n",
       "\n",
       "        [[ 0.0211,  0.0557,  0.2625,  0.1923],\n",
       "         [ 0.1903,  0.2360,  0.1382,  0.1859]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last output is the output of RRR. We can get it by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0211, 0.0557, 0.2625, 0.1923],\n",
       "        [0.1903, 0.2360, 0.1382, 0.1859]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convient to have batches as the first dimension of the input. One can do it by adding `batch_first=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4907, -1.0625,  0.2827],\n",
       "         [-1.1621,  0.9900, -0.2673],\n",
       "         [-0.0923,  0.5844,  3.0635],\n",
       "         [ 0.6826,  0.6106,  1.3191],\n",
       "         [ 1.0280, -1.5714,  1.5271],\n",
       "         [ 0.2480, -1.4963, -0.6572],\n",
       "         [ 0.5456,  0.4040, -0.1535],\n",
       "         [-0.6119, -1.3854,  0.8752],\n",
       "         [ 1.4831, -0.1826, -1.7904],\n",
       "         [ 0.2595, -0.7559,  0.9015]],\n",
       "\n",
       "        [[-0.7472,  1.1277,  0.6444],\n",
       "         [-2.2725,  0.6541, -0.9927],\n",
       "         [ 0.0994, -1.6477,  0.0856],\n",
       "         [ 1.3480, -0.5456, -1.0172],\n",
       "         [-0.0205,  1.1389, -1.0796],\n",
       "         [-0.6449,  0.0679, -1.2483],\n",
       "         [-1.4658,  2.0072, -3.1096],\n",
       "         [ 0.6833, -0.7477,  0.5068],\n",
       "         [ 1.1615,  0.8511,  0.8350],\n",
       "         [-0.7869, -0.9565,  1.2470]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_batch_first = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True) \n",
    "inputs_batch_first = torch.randn(batch_size, seq_len, input_size)\n",
    "inputs_batch_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0348,  0.1034,  0.2218, -0.2388],\n",
       "         [-0.2543,  0.1988,  0.1634, -0.2615],\n",
       "         [-0.2844,  0.0665,  0.2403, -0.0455],\n",
       "         [-0.3628,  0.1032,  0.2150, -0.0100],\n",
       "         [ 0.0965, -0.1670,  0.1680, -0.0118],\n",
       "         [ 0.3601, -0.0077,  0.1550, -0.0782],\n",
       "         [ 0.0623,  0.1175,  0.1592, -0.0867],\n",
       "         [ 0.1381, -0.0117,  0.2611, -0.1187],\n",
       "         [ 0.2118,  0.1741,  0.1319, -0.0632],\n",
       "         [ 0.0944,  0.0303,  0.2591, -0.0843]],\n",
       "\n",
       "        [[-0.1982,  0.1185,  0.1512, -0.1193],\n",
       "         [-0.2959,  0.2146,  0.1699, -0.3551],\n",
       "         [ 0.1608,  0.0091,  0.2493, -0.1322],\n",
       "         [ 0.2374,  0.0966,  0.1648, -0.0909],\n",
       "         [-0.1051,  0.2336,  0.1304, -0.1782],\n",
       "         [-0.1333,  0.2966,  0.1963, -0.2213],\n",
       "         [-0.3090,  0.3673,  0.0648, -0.4083],\n",
       "         [-0.0439,  0.1211,  0.2816, -0.1242],\n",
       "         [-0.1705,  0.1398,  0.2142, -0.0329],\n",
       "         [-0.0741,  0.0487,  0.2913, -0.1061]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm_batch_first(inputs_batch_first)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the finial output by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0944,  0.0303,  0.2591, -0.0843],\n",
       "        [-0.0741,  0.0487,  0.2913, -0.1061]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 42, 35, 98, 95,  6, 21, 33, 27, 33],\n",
       "        [67, 85, 76, 73, 56, 27,  8, 58,  4, 58]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = 100\n",
    "sentences = torch.randint(dict_size, (batch_size, seq_len))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(dict_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4900,  0.6828, -0.0091],\n",
       "         [ 0.8041, -0.5027, -0.4872],\n",
       "         [-1.5296, -0.5593,  1.8563],\n",
       "         [ 0.8346,  0.9135,  0.8640],\n",
       "         [ 1.1959, -1.2311,  0.8479],\n",
       "         [ 0.0538, -0.3251,  1.6505],\n",
       "         [-0.9990, -0.1155, -0.2359],\n",
       "         [ 0.6846, -1.9279,  0.0409],\n",
       "         [-0.6241, -1.8352,  0.7764],\n",
       "         [ 0.6846, -1.9279,  0.0409]],\n",
       "\n",
       "        [[-0.9298, -0.2720,  0.0940],\n",
       "         [ 0.2911,  1.2806,  0.5875],\n",
       "         [-1.2048, -0.2818, -0.5763],\n",
       "         [ 0.3502, -0.4809, -0.9507],\n",
       "         [ 0.1779, -0.0298,  1.3856],\n",
       "         [-0.6241, -1.8352,  0.7764],\n",
       "         [ 0.1574, -1.1280,  0.9305],\n",
       "         [ 0.4265,  1.7688,  0.1390],\n",
       "         [ 0.7498,  1.5912, -0.4242],\n",
       "         [ 0.4265,  1.7688,  0.1390]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_embedded = embedding(sentences)\n",
    "sentences_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4601, -0.1886,  0.1285, -0.0948],\n",
       "        [-0.2886,  0.2626,  0.1946, -0.0192]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, _ = lstm_batch_first(sentences_embedded)\n",
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)\n",
    "\n",
    "Next we consider a dataset with text and the goal is to evaluate whether they are toxic or non-toxic.\n",
    "\n",
    "You can download the dataset in the following link:\n",
    "\n",
    "[here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_df = pd.read_csv(\"data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "comments_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27250</th>\n",
       "      <td>I'm afraid that you didn't follow the history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133958</th>\n",
       "      <td>Drmies, you really need to be de-syoped.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text\n",
       "27250   I'm afraid that you didn't follow the history ...\n",
       "133958           Drmies, you really need to be de-syoped."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label_colnames = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(comments_df[['comment_text']], comments_df[label_colnames], random_state=667)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "class TextPreprocessor:\n",
    "        \n",
    "    def transfrom_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(BAD_SYMBOLS_RE, \" \", text) # process bad symbols\n",
    "        # text = \" \".join([STEMMER.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda text: self.transfrom_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "X_train_preprocessed = preprocessor.transform(X_train['comment_text'])\n",
    "X_test_preprocessed = preprocessor.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid that you didn't follow the history of all this. (1) I don't want to obtain an email, I want to write it. (2) Every time when someone makes a remark, I tend to think that I am obligated to reply, since otherwise that person may think  that I neglect him/her, and don't think him or her worthy of a reply. But that leaves me no time to write that email. (3) Also, if I would take that time, then Rspeer could delete all my contributions in the mean time, as he already has started to do,  making it hard work again to restore it. (4) I recognize that wikipedia can be accessed any time of the day, but it might be proper for you and Rspeer and others reading my request for a time out to respect my wish for it. (5) Rspeer started  this discussion about my conduct on this talk page, by saying that there was a threat, while there wasn't. Now, do I have to take this seriously ? And have this nonsense here ? (6) Should I have entered my criticism on his behaviour on his talk page, instead of the borda fixed point page, where he occluded the argument on the article with his behavior ? (7) My impression now is that I have to ask for mediation to get some quiet time to formulate my argument on the integrity of science for the professors. True of false ?\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "i m afraid that you didn t follow the history of all this   1  i don t want to obtain an email  i want to write it   2  every time when someone makes a remark  i tend to think that i am obligated to reply  since otherwise that person may think  that i neglect him her  and don t think him or her worthy of a reply  but that leaves me no time to write that email   3  also  if i would take that time  then rspeer could delete all my contributions in the mean time  as he already has started to do   making it hard work again to restore it   4  i recognize that wikipedia can be accessed any time of the day  but it might be proper for you and rspeer and others reading my request for a time out to respect my wish for it   5  rspeer started  this discussion about my conduct on this talk page  by saying that there was a threat  while there wasn t  now  do i have to take this seriously   and have this nonsense here    6  should i have entered my criticism on his behaviour on his talk page  instead of the borda fixed point page  where he occluded the argument on the article with his behavior    7  my impression now is that i have to ask for mediation to get some quiet time to formulate my argument on the integrity of science for the professors  true of false  \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[0])\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "print(X_train_preprocessed.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drmies, you really need to be de-syoped.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "drmies  you really need to be de syoped \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[1])\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print(X_train_preprocessed.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(text):\n",
    "    word_set = set()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "    word_list = [\"<UNK>\", \"<PAD>\"] + sorted(list(word_set))\n",
    "    word2idx = {word_list[idx]: idx for idx in range(len(word_list))}\n",
    "    idx2word = {idx: word_list[idx] for idx in range(len(word_list))}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2idx = None\n",
    "        self.idx2word = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        text = \" \".join(X)\n",
    "        self.word2idx, self.idx2word = create_dicts(text)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.transform_line(line) for line in X]\n",
    "        \n",
    "    def transform_line(self, line):\n",
    "        return [self.word2idx.get(word, 0) for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(X_train_preprocessed)\n",
    "tokenizer.fit(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.transform(X_train_preprocessed)\n",
    "X_test_tokenized = tokenizer.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutter:\n",
    "\n",
    "    def __init__(self, size=150):\n",
    "        self.size = size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        new_X = []\n",
    "        for line in X:\n",
    "            new_line = line[:self.size]\n",
    "            new_line = new_line + [1] * (self.size - len(new_line))\n",
    "            new_X.append(new_line)\n",
    "        return new_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = Cutter()\n",
    "X_train_cutted = cutter.transform(X_train_tokenized)\n",
    "X_test_cutted = cutter.transform(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(y_train.values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.tensor(X_train_cutted), torch.from_numpy(y_train.values).float())\n",
    "test_data = TensorDataset(torch.tensor(X_test_cutted), torch.from_numpy(y_test.values).float())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, dict_size, output_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(dict_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeded)\n",
    "        lstm_out = lstm_out[:, -1]        \n",
    "        logits = self.fc(lstm_out)\n",
    "        out = self.sigmoid(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(tokenizer.word2idx)\n",
    "output_size = len(label_colnames)\n",
    "embedding_dim = 3\n",
    "hidden_dim = 4\n",
    "\n",
    "lstm_model = LSTMModel(dict_size, output_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(80503, 3)\n",
       "  (lstm): LSTM(3, 4, batch_first=True)\n",
       "  (fc): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.load_state_dict(torch.load(\"models/lstm_model.pt\"))\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([119678, 150])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch = torch.tensor(X_train_cutted)\n",
    "X_test_torch = torch.tensor(X_test_cutted)\n",
    "X_train_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5850, 0.5777, 0.6186, 0.5786, 0.4990, 0.5299],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        ...,\n",
       "        [0.5823, 0.5669, 0.6228, 0.5842, 0.4854, 0.5107],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5809, 0.5654, 0.6273, 0.5782, 0.4876, 0.5226],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5857, 0.5606, 0.6211, 0.5823, 0.4909, 0.5153],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5864, 0.5396, 0.5886, 0.5772, 0.5035, 0.4905],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456],\n",
       "        [0.5815, 0.5733, 0.6623, 0.5828, 0.4724, 0.5456]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "input_data, labels = dataiter.next()\n",
    "lstm_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 300, Avg. Loss: 0.14560839037100473\n",
      "Epoch: 1, Batch: 600, Avg. Loss: 0.13462490256875753\n",
      "Epoch: 1, Batch: 900, Avg. Loss: 0.13814253223439057\n",
      "Epoch: 1, Batch: 1200, Avg. Loss: 0.14827531855553389\n",
      "Epoch: 1, Batch: 1500, Avg. Loss: 0.14399336186548073\n",
      "Epoch: 1, Batch: 1800, Avg. Loss: 0.14149823609739542\n",
      "Epoch: 1, Batch: 2100, Avg. Loss: 0.13821697560449442\n",
      "Epoch: 1, Batch: 2400, Avg. Loss: 0.14182119390616815\n",
      "Epoch: 1, Batch: 2700, Avg. Loss: 0.14258459359407424\n",
      "Epoch: 1, Batch: 3000, Avg. Loss: 0.14466992820302646\n",
      "Epoch: 1, Batch: 3300, Avg. Loss: 0.13454586534450452\n",
      "Epoch: 1, Batch: 3600, Avg. Loss: 0.14178564857691525\n",
      "Epoch: 2, Batch: 300, Avg. Loss: 0.14257890628029904\n",
      "Epoch: 2, Batch: 600, Avg. Loss: 0.13574930414557457\n",
      "Epoch: 2, Batch: 900, Avg. Loss: 0.14134988454480965\n",
      "Epoch: 2, Batch: 1200, Avg. Loss: 0.14603582815577587\n",
      "Epoch: 2, Batch: 1500, Avg. Loss: 0.13847442239522934\n",
      "Epoch: 2, Batch: 1800, Avg. Loss: 0.1405187136059006\n",
      "Epoch: 2, Batch: 2100, Avg. Loss: 0.13655391532927752\n",
      "Epoch: 2, Batch: 2400, Avg. Loss: 0.14236501307537158\n",
      "Epoch: 2, Batch: 2700, Avg. Loss: 0.1391194626564781\n",
      "Epoch: 2, Batch: 3000, Avg. Loss: 0.13357317763070264\n",
      "Epoch: 2, Batch: 3300, Avg. Loss: 0.14111933505783478\n",
      "Epoch: 2, Batch: 3600, Avg. Loss: 0.14439380531509718\n",
      "Epoch: 3, Batch: 300, Avg. Loss: 0.14157959785312413\n",
      "Epoch: 3, Batch: 600, Avg. Loss: 0.13136457275599242\n",
      "Epoch: 3, Batch: 900, Avg. Loss: 0.09653974389036496\n",
      "Epoch: 3, Batch: 1200, Avg. Loss: 0.09045854744501412\n",
      "Epoch: 3, Batch: 1500, Avg. Loss: 0.07855265798047185\n",
      "Epoch: 3, Batch: 1800, Avg. Loss: 0.07098163422662765\n",
      "Epoch: 3, Batch: 2100, Avg. Loss: 0.06826403044629842\n",
      "Epoch: 3, Batch: 2400, Avg. Loss: 0.0671535475552082\n",
      "Epoch: 3, Batch: 2700, Avg. Loss: 0.06321291134692729\n",
      "Epoch: 3, Batch: 3000, Avg. Loss: 0.06201048018100361\n",
      "Epoch: 3, Batch: 3300, Avg. Loss: 0.06326787383295596\n",
      "Epoch: 3, Batch: 3600, Avg. Loss: 0.06381758627016097\n",
      "Epoch: 4, Batch: 300, Avg. Loss: 0.05295702457583199\n",
      "Epoch: 4, Batch: 600, Avg. Loss: 0.05652357431439062\n",
      "Epoch: 4, Batch: 900, Avg. Loss: 0.05476310261990875\n",
      "Epoch: 4, Batch: 1200, Avg. Loss: 0.0525747970227773\n",
      "Epoch: 4, Batch: 1500, Avg. Loss: 0.053274034452624616\n",
      "Epoch: 4, Batch: 1800, Avg. Loss: 0.05505183787550777\n",
      "Epoch: 4, Batch: 2100, Avg. Loss: 0.052657870021648706\n",
      "Epoch: 4, Batch: 2400, Avg. Loss: 0.05684548866779854\n",
      "Epoch: 4, Batch: 2700, Avg. Loss: 0.05682216721198832\n",
      "Epoch: 4, Batch: 3000, Avg. Loss: 0.05121334139800941\n",
      "Epoch: 4, Batch: 3300, Avg. Loss: 0.05675592516859373\n",
      "Epoch: 4, Batch: 3600, Avg. Loss: 0.05674496269474427\n",
      "Epoch: 5, Batch: 300, Avg. Loss: 0.04939087770025556\n",
      "Epoch: 5, Batch: 600, Avg. Loss: 0.05038248285884037\n",
      "Epoch: 5, Batch: 900, Avg. Loss: 0.04959624287245485\n",
      "Epoch: 5, Batch: 1200, Avg. Loss: 0.0503617266829436\n",
      "Epoch: 5, Batch: 1500, Avg. Loss: 0.051236565282257895\n",
      "Epoch: 5, Batch: 1800, Avg. Loss: 0.04881696645636111\n",
      "Epoch: 5, Batch: 2100, Avg. Loss: 0.04959668122464791\n",
      "Epoch: 5, Batch: 2400, Avg. Loss: 0.04998037331194306\n",
      "Epoch: 5, Batch: 2700, Avg. Loss: 0.0506569011156292\n",
      "Epoch: 5, Batch: 3000, Avg. Loss: 0.048873319160969306\n",
      "Epoch: 5, Batch: 3300, Avg. Loss: 0.049650963780780634\n",
      "Epoch: 5, Batch: 3600, Avg. Loss: 0.05252971528020377\n",
      "Epoch: 6, Batch: 300, Avg. Loss: 0.04684446719669116\n",
      "Epoch: 6, Batch: 600, Avg. Loss: 0.04487552119845835\n",
      "Epoch: 6, Batch: 900, Avg. Loss: 0.044820075269478066\n",
      "Epoch: 6, Batch: 1200, Avg. Loss: 0.048208005231960366\n",
      "Epoch: 6, Batch: 1500, Avg. Loss: 0.047227971527415015\n",
      "Epoch: 6, Batch: 1800, Avg. Loss: 0.04649183134005094\n",
      "Epoch: 6, Batch: 2100, Avg. Loss: 0.047699308679051075\n",
      "Epoch: 6, Batch: 2400, Avg. Loss: 0.04301074649284904\n",
      "Epoch: 6, Batch: 2700, Avg. Loss: 0.04726088469964452\n",
      "Epoch: 6, Batch: 3000, Avg. Loss: 0.04853146151561911\n",
      "Epoch: 6, Batch: 3300, Avg. Loss: 0.04580007317631195\n",
      "Epoch: 6, Batch: 3600, Avg. Loss: 0.0486845893987144\n",
      "Epoch: 7, Batch: 300, Avg. Loss: 0.04143071464340513\n",
      "Epoch: 7, Batch: 600, Avg. Loss: 0.04224594916993131\n",
      "Epoch: 7, Batch: 900, Avg. Loss: 0.04338180389643336\n",
      "Epoch: 7, Batch: 1200, Avg. Loss: 0.04306213819091984\n",
      "Epoch: 7, Batch: 1500, Avg. Loss: 0.04389846334893567\n",
      "Epoch: 7, Batch: 1800, Avg. Loss: 0.04543588273071995\n",
      "Epoch: 7, Batch: 2100, Avg. Loss: 0.043772834551831084\n",
      "Epoch: 7, Batch: 2400, Avg. Loss: 0.04263579022527362\n",
      "Epoch: 7, Batch: 2700, Avg. Loss: 0.046003560027262816\n",
      "Epoch: 7, Batch: 3000, Avg. Loss: 0.046296756838370735\n",
      "Epoch: 7, Batch: 3300, Avg. Loss: 0.04392915396019816\n",
      "Epoch: 7, Batch: 3600, Avg. Loss: 0.04500434385612607\n",
      "Epoch: 8, Batch: 300, Avg. Loss: 0.03955179152777419\n",
      "Epoch: 8, Batch: 600, Avg. Loss: 0.04244808599352837\n",
      "Epoch: 8, Batch: 900, Avg. Loss: 0.0393863095047224\n",
      "Epoch: 8, Batch: 1200, Avg. Loss: 0.04043293412444958\n",
      "Epoch: 8, Batch: 1500, Avg. Loss: 0.03993588427663781\n",
      "Epoch: 8, Batch: 1800, Avg. Loss: 0.041530549643794074\n",
      "Epoch: 8, Batch: 2100, Avg. Loss: 0.04151516506390181\n",
      "Epoch: 8, Batch: 2400, Avg. Loss: 0.044301631022632744\n",
      "Epoch: 8, Batch: 2700, Avg. Loss: 0.043875610500302475\n",
      "Epoch: 8, Batch: 3000, Avg. Loss: 0.04111735723602275\n",
      "Epoch: 8, Batch: 3300, Avg. Loss: 0.041795151798675455\n",
      "Epoch: 8, Batch: 3600, Avg. Loss: 0.03990312973745555\n",
      "Epoch: 9, Batch: 300, Avg. Loss: 0.03835134876756153\n",
      "Epoch: 9, Batch: 600, Avg. Loss: 0.038905925272944536\n",
      "Epoch: 9, Batch: 900, Avg. Loss: 0.04029843877069652\n",
      "Epoch: 9, Batch: 1200, Avg. Loss: 0.038637994568174086\n",
      "Epoch: 9, Batch: 1500, Avg. Loss: 0.04009030214510858\n",
      "Epoch: 9, Batch: 1800, Avg. Loss: 0.03881741764441055\n",
      "Epoch: 9, Batch: 2100, Avg. Loss: 0.03759805164008867\n",
      "Epoch: 9, Batch: 2400, Avg. Loss: 0.040162702826200984\n",
      "Epoch: 9, Batch: 2700, Avg. Loss: 0.03959071351971943\n",
      "Epoch: 9, Batch: 3000, Avg. Loss: 0.03918741905266264\n",
      "Epoch: 9, Batch: 3300, Avg. Loss: 0.04054353908596871\n",
      "Epoch: 9, Batch: 3600, Avg. Loss: 0.04166477025661152\n",
      "Epoch: 10, Batch: 300, Avg. Loss: 0.03923031907683859\n",
      "Epoch: 10, Batch: 600, Avg. Loss: 0.03431240671847869\n",
      "Epoch: 10, Batch: 900, Avg. Loss: 0.037088935110659804\n",
      "Epoch: 10, Batch: 1200, Avg. Loss: 0.03526715701766079\n",
      "Epoch: 10, Batch: 1500, Avg. Loss: 0.03760444437415572\n",
      "Epoch: 10, Batch: 1800, Avg. Loss: 0.04026592885299275\n",
      "Epoch: 10, Batch: 2100, Avg. Loss: 0.03812492713293371\n",
      "Epoch: 10, Batch: 2400, Avg. Loss: 0.03918840973987244\n",
      "Epoch: 10, Batch: 2700, Avg. Loss: 0.040488337186689025\n",
      "Epoch: 10, Batch: 3000, Avg. Loss: 0.037414105746041364\n",
      "Epoch: 10, Batch: 3300, Avg. Loss: 0.039483002344786654\n",
      "Epoch: 10, Batch: 3600, Avg. Loss: 0.038311089931812606\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "print_every = 300\n",
    "\n",
    "loss_over_time = [] # to track the loss as the network trains\n",
    "    \n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_i, (input_data, labels) in enumerate(train_loader):\n",
    "        # Zero gradients (just in case)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate predictions\n",
    "        output = lstm_model(input_data) \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        ## Backward propagation\n",
    "        loss.backward()\n",
    "        ## Upade weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss statistics\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        if batch_i % print_every ==  print_every - 1:    # print everyx batches (\n",
    "                avg_loss = running_loss/print_every\n",
    "                # record and print the avg loss over the 100 batches\n",
    "                loss_over_time.append(avg_loss)\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model's state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight \t torch.Size([80503, 3])\n",
      "lstm.weight_ih_l0 \t torch.Size([16, 3])\n",
      "lstm.weight_hh_l0 \t torch.Size([16, 4])\n",
      "lstm.bias_ih_l0 \t torch.Size([16])\n",
      "lstm.bias_hh_l0 \t torch.Size([16])\n",
      "fc.weight \t torch.Size([6, 4])\n",
      "fc.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(), \"models/lstm_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_classification(y, y_hat, y_proba):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y, y_hat),\n",
    "        \"Precision\": precision_score(y, y_hat),\n",
    "        \"Recall\": recall_score(y, y_hat),\n",
    "        \"F1-score\": f1_score(y, y_hat),\n",
    "        \"AUC\": roc_auc_score(y, y_proba),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_classes = len(label_colnames)\n",
    "# initialize tensor and lists to monitor test loss and accuracy\n",
    "test_loss = torch.zeros(1)\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "# set the module to evaluation mode\n",
    "lstm_model.eval()\n",
    "\n",
    "# get the input images and their corresponding labels\n",
    "inputs, labels = test_loader.dataset.tensors\n",
    "\n",
    "# forward pass to get outputs\n",
    "outputs = lstm_model(inputs)\n",
    "\n",
    "# calculate the loss\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# update average test loss \n",
    "test_loss = test_loss + ((torch.ones(1) / (len(labels) + 1)) * (loss.data - test_loss))\n",
    "\n",
    "# get the predicted class from the maximum value in the output-list of class scores\n",
    "metrics = {}\n",
    "for j in range(num_classes):\n",
    "    # compare predictions to true label\n",
    "    predicted_class = np.round(outputs.data[:,j])\n",
    "    labels_class = labels.data[:,j]\n",
    "    class_total[j] = len(labels)\n",
    "    class_correct[j] = (labels_class==predicted_class).sum()\n",
    "    metrics[label_colnames[j]] = evaluate_classification(labels_class, predicted_class, outputs.data[:,j])\n",
    "    #(predicted_class == labels_class).sum()\n",
    "              \n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "{'Accuracy': 0.9477602586920011, 'Precision': 0.7159542743538767, 'Recall': 0.7537938252223967, 'F1-score': 0.7343869487637013, 'AUC': 0.9561843704348368}\n",
      "severe_toxic\n",
      "{'Accuracy': 0.990223848795528, 'Precision': 0.5416666666666666, 'Recall': 0.1306532663316583, 'F1-score': 0.21052631578947367, 'AUC': 0.9878841288350857}\n",
      "obscene\n",
      "{'Accuracy': 0.9739803975634823, 'Precision': 0.7562776957163959, 'Recall': 0.7388167388167388, 'F1-score': 0.7474452554744526, 'AUC': 0.9775161913126688}\n",
      "threat\n",
      "{'Accuracy': 0.9970420875842879, 'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0, 'AUC': 0.934731594029978}\n",
      "insult\n",
      "{'Accuracy': 0.9682651091670218, 'Precision': 0.6803848209513629, 'Recall': 0.6558475012879958, 'F1-score': 0.667890870933893, 'AUC': 0.9728496631879917}\n",
      "identity_hate\n",
      "{'Accuracy': 0.9911262627528639, 'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0, 'AUC': 0.9452301475065097}\n"
     ]
    }
   ],
   "source": [
    "for label in metrics:\n",
    "    print(label)\n",
    "    print(metrics[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9780663274258643, 'Precision': 0.4490472429480504, 'Recall': 0.3798518886097983, 'F1-score': 0.39337489849358676, 'AUC': 0.9623993492178452}\n"
     ]
    }
   ],
   "source": [
    "total_evaluation = {}\n",
    "for metric in metrics['toxic']:\n",
    "    total_evaluation[metric] = 0\n",
    "    for label in metrics:\n",
    "        total_evaluation[metric] += metrics[label][metric]\n",
    "    total_evaluation[metric] /= num_classes\n",
    "print(total_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
